{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "033e90e4-0dd2-46d4-80bd-1c43a27fcaa4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express as px\n",
    "\n",
    "import ast\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import networkx as nx\n",
    "import random\n",
    "import json\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0cf66c-e298-4357-9bd6-ec425a202878",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca2a11-d9b9-4b5b-adeb-13fa3229ff39",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load in Tweet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b83c72-cff6-451d-b8e3-a7fe020cc7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/jchang153/Documents/UCLA-CAM/GV KG/Data/Tweets/All/bigbabies/bigbaby_r_t_30_s.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140bdbe6-7876-43f4-ada8-4ec7e629de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating strings of lists as lists\n",
    "df['hashtags'] = df['hashtags'].apply(ast.literal_eval)\n",
    "df['mentions'] = df['mentions'].apply(ast.literal_eval)\n",
    "# df['keywords'] = df['keywords'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d35eca1-be24-4682-b18c-a2a46febf45b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['created_at', 'tweet_id', 'text', 'in_reply_to_tweet_id',\n",
       "       'in_reply_to_user_id', 'geo', 'quote_count', 'reply_count',\n",
       "       'retweet_count', 'favorite_count', 'lang', 'quoted_tweet_id',\n",
       "       'possibly_sensitive', 'user_id', 'screen_name', 'followers_count',\n",
       "       'friends_count', 'statuses_count', 'verified', 'hashtags', 'mentions',\n",
       "       'date', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
       "       '12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:35]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9947c53-ece9-4ac8-8147-f41738d76fdb",
   "metadata": {},
   "source": [
    "### Load in Crime Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c3f8dc-6d17-40c9-8263-5a59b1dffbf6",
   "metadata": {},
   "source": [
    "Load in the hate crime `hatecrimedata.csv` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94eed177-05c6-4372-86bf-54efa9cead37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = pd.read_csv('/Users/jchang153/Documents/UCLA-CAM/GV KG/Data/hatecrimedata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "225c64fe-abcb-4b0f-94d2-dfdd3e75c914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# limiting to only dates that have associated tweets\n",
    "df_crime['incident_date'] = pd.to_datetime(df_crime['incident_date'])\n",
    "start_date = pd.to_datetime('2020-03-11')\n",
    "end_date = pd.to_datetime('2021-06-17')\n",
    "\n",
    "df_crime = df_crime[(df_crime['incident_date'] >= start_date) & (df_crime['incident_date'] <= end_date)]\n",
    "df_crime['incident_date'] = pd.to_datetime(df_crime['incident_date']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b08743d-1260-49f9-86b7-d2d98d5ecc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = df_crime[df_crime['state_name'] == 'California']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fd1424-c288-4c47-831e-bc0f87a85b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['incident_id', 'data_year', 'ori', 'pug_agency_name', 'pub_agency_unit',\n",
       "       'agency_type_name', 'state_abbr', 'state_name', 'division_name',\n",
       "       'region_name', 'population_group_code', 'population_group_description',\n",
       "       'incident_date', 'adult_victim_count', 'juvenile_victim_count',\n",
       "       'total_offender_count', 'adult_offender_count',\n",
       "       'juvenile_offender_count', 'offender_race', 'offender_ethnicity',\n",
       "       'victim_count', 'offense_name', 'total_individual_victims',\n",
       "       'location_name', 'bias_desc', 'victim_types', 'multiple_offense',\n",
       "       'multiple_bias'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crime.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44143e62-3b3b-4f47-90d5-148e1a0b3e20",
   "metadata": {},
   "source": [
    "### Load in Topic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f5cbe71-81e4-4889-a6c2-6f656114cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_info = pd.read_csv('/Users/jchang153/Documents/UCLA-CAM/GV KG/Data/Tweets/All/topics/bigbaby_r_30_docs.csv')\n",
    "top_info = pd.read_csv('/Users/jchang153/Documents/UCLA-CAM/GV KG/Data/Tweets/All/topics/bigbaby_r_30_tops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5562ad2d-49ea-4e3c-ab65-dd48a2101399",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_info['Representation'] = top_info['Representation'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa98af60-d1f6-4360-ad63-093ebe67f12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Topic', 'Count', 'Name', 'Representation', 'Representative_Docs'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_info.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cde706b-32d4-4ba1-9cee-7f7104f4d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "top2name = top_info.set_index('Topic')['Name'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb01a40a-a4be-4873-9b59-a53d8a2c7519",
   "metadata": {},
   "source": [
    "### Querying by a Given Group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c3fe1-d41a-4359-9f90-c5a5fc9399a6",
   "metadata": {},
   "source": [
    "Only black-related topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00574575-8f8d-496a-9b3e-b42e6062f2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [32,35,65,135,142]\n",
    "black_topics = [1,2,3,4,7,8,9,11,13,15,19,20,21,23,25,27,31,34,36,38,40,41,42,44,45,46,47,48,50,\n",
    "51,52,56,62,63,64,66,68,70,71,73,75,76,78,82,83,84,86,88,92,93,94,101,102,105,106,\n",
    "107,109,111,114,117,119,120, 121,122,123,124,125,126,131,132,133,137,140,143,144,145,\n",
    "146,147,149,150,151,153,154,155,157,160,162,163,164,165,166,168,169,171,172,177,178,179,\n",
    "180,184,186,187,188,191,193,196,200,202,203,206,208,211,212,216,218,220,222,223,224,225,\n",
    "226,228,229,230,233,235,242,244,245,250,251,253,254,255,256,259,260,261,266,268,269]\n",
    "\n",
    "lgbt_topics = [28,26,58,175,57,209,22,53,168,180,18,156,182,104,215,247]\n",
    "\n",
    "jewish_topics = [79,24,72,0,30,37,55,87,91,129,121,129,199,205,264,10,59,5,6,100,262]\n",
    "\n",
    "asian_topics = [67,69,96,115,135,147,161,16,99,183,195,201,221,243,101]\n",
    "\n",
    "hispanic_topics = [32,35,65,135,142]\n",
    "\n",
    "top_list = black_topics + lgbt_topics + asian_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53cd615f-a36e-4aed-9515-d7f9b98c1adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141, 16, 15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(black_topics), len(lgbt_topics), len(asian_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16a4a669-6083-4736-88f1-0b72c6b392cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a786889d-eed1-437f-b333-74664a30230d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25467, 3088, 1846)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['topics'].isin(black_topics)]), len(df[df['topics'].isin(lgbt_topics)]), len(df[df['topics'].isin(asian_topics)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6300c7-1d38-43cc-9e16-6fb2ca07595e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6530242-f80f-4949-b1b8-e4b1e1d1df6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63a36ff1-e7fe-4b55-988a-466c04e39a1a",
   "metadata": {},
   "source": [
    "Only tweets who have at least 0.01 probability of being in one of the above topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1b05500-9ad0-436c-b228-0bf3f9e2df7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51491"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df[[str(num) for num in top_list]].ge(0.01).any(axis=1)]\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856516a1-68ec-42a2-a0fa-3ea8e1c6370d",
   "metadata": {},
   "source": [
    "Only black crimes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a31da5e-16e5-4991-b77b-417f4ecce80b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Anti-Jewish', 'Anti-Gay (Male)', 'Anti-Black or African American',\n",
       "       'Anti-Hindu', 'Anti-Transgender', 'Anti-Hispanic or Latino',\n",
       "       'Anti-Multiple Races, Group', 'Anti-Asian',\n",
       "       'Anti-Mental Disability', 'Anti-White',\n",
       "       'Anti-Other Race/Ethnicity/Ancestry', 'Anti-Female',\n",
       "       'Anti-Other Religion',\n",
       "       'Anti-Lesbian, Gay, Bisexual, or Transgender (Mixed Group)',\n",
       "       'Anti-Islamic (Muslim)', 'Anti-Arab', 'Anti-Lesbian (Female)',\n",
       "       'Anti-Other Christian', 'Anti-Physical Disability',\n",
       "       'Anti-Multiple Religions, Group', 'Anti-Sikh',\n",
       "       'Anti-Gender Non-Conforming',\n",
       "       'Anti-American Indian or Alaska Native', 'Anti-Bisexual',\n",
       "       'Anti-Protestant', 'Anti-Eastern Orthodox (Russian, Greek, Other)',\n",
       "       'Anti-Buddhist', 'Anti-Catholic', 'Anti-Church of Jesus Christ',\n",
       "       'Anti-Black or African American;Anti-Hispanic or Latino',\n",
       "       'Anti-Gay (Male);Anti-Hispanic or Latino',\n",
       "       'Anti-Asian;Anti-Black or African American'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_crime['bias_desc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68f1aa3c-dff0-4f38-ae48-092e265d04b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_crime = df_crime[df_crime['bias_desc'].str.contains('Black')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb2eb7-e77f-4c71-8e6d-ec890af749ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building the KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2eac882-095e-46f7-bee1-f1377426983c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# turns the dataframes into lists of dictionaries\n",
    "tweet_dict = df.to_dict(orient='records')\n",
    "crime_dict = df_crime.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294f0aaf-7d92-43c0-aff0-895d11a9d9c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Getting unique entities, hashtags, topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd89f20f-9be7-4ead-b0ec-883b2297d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = set()\n",
    "tags = set()\n",
    "topics = set()\n",
    "\n",
    "for tweet in tqdm(tweet_dict):\n",
    "    entities.add((tweet['tweet_id'], 't'))\n",
    "    # entities.add(tweet['screen_name']) # this one gives less entities, indicating some repeated screen names\n",
    "    # entities.add((tweet['user_id'], 'u'))\n",
    "    entities.add(tweet['date'])\n",
    "    entities.add(tweet['topic'])\n",
    "    \n",
    "    # topics.add(tweet['topic'])\n",
    "\n",
    "    # for tag in tweet['hashtags']:\n",
    "    #     entities.add(tag)\n",
    "    #     tags.add(tag)\n",
    "        \n",
    "for crime in crime_dict:\n",
    "    entities.add((crime['incident_id'], 'c')) \n",
    "    entities.add(crime['incident_date']) # in case not all are captured in tweets\n",
    "\n",
    "entities = entities | groups\n",
    "# entities.add('negative_sentiment')\n",
    "# entities.add('positive_sentiment')\n",
    "# entities.add('neutral_sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93ea7497-acb0-468a-a29e-981e4c1af964",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2959/2959 [00:00<00:00, 158278.65it/s]\n"
     ]
    }
   ],
   "source": [
    "entities = set()\n",
    "\n",
    "for tweet in tqdm(tweet_dict):\n",
    "    entities.add((tweet['tweet_id'], 't'))\n",
    "    # consider adding: sentiment, quote_count, reply_count, retweet_count, favorite_count, lang, possibly_sensitive\n",
    "    entities.add((tweet['user_id'], 'u'))\n",
    "    # consider adding: followers_count, friends_count, statuses_count, verified\n",
    "    entities.add(tweet['date'])\n",
    "        \n",
    "for crime in crime_dict:\n",
    "    entities.add((crime['incident_id'], 'c')) \n",
    "    entities.add(crime['incident_date']) # in case not all are captured in tweets\n",
    "    \n",
    "for top in top_list:\n",
    "    entities.add(top2name[top])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa244d6-f63b-46ec-8a94-5ff739670bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5825\n"
     ]
    }
   ],
   "source": [
    "print(len(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48363770-0ec3-4704-83ec-1018b9bd36ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_list = list(entities)\n",
    "entity2id = {k:v for v,k in enumerate(ent_list)}\n",
    "id2entity = {v:k for v,k in enumerate(ent_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6994927-aa0d-4274-98a8-07891168097f",
   "metadata": {},
   "source": [
    "### Creating relation dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f81a94ca-cd16-44ad-83d3-bc5925b330d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = ['tweeted_on', 'tweeted', 'in_topic', 'mentioned', 'replied_to', 'occurred_on']\n",
    "\n",
    "relation2id = {}\n",
    "id2relation = {}\n",
    "j = 0 \n",
    "for r in relations:\n",
    "    relation2id[r] = j\n",
    "    id2relation[j] = r\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a571a24e-f338-4739-8367-83ba79f92420",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba90e320-bebc-4008-9e79-70506ce61baf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mentions, Quotes, Replies Triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d206aa-53a2-49a4-a53d-6b2edd1ca4c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exploring replies, quotes, mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c5852d-59a6-4e60-af6a-b6ea52f4f10d",
   "metadata": {},
   "source": [
    "Number of users that were replied to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "cd570838-49b2-4698-9495-dbaca07ed441",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_replied_users = df.dropna(subset='in_reply_to_user_id')['in_reply_to_user_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1ff79363-c385-422a-8b0f-2a04dede666c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12202, 8729)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_replied_users), len(set(all_replied_users))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269269b-54a9-4004-bb93-b5c5c2d1cafb",
   "metadata": {},
   "source": [
    "Number of users replied to in our dataset (not counting multiplicity, e.g., if a given user in our dataset was replied to multiple times, this would become multiple triples, but here we are just counting how many unique users that were replied to that are among the unique users in our dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "eb39d1e7-64bd-4995-b349-a2f6f52bc655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1249"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['user_id']).intersection(set(all_replied_users)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0685bd10-45a4-48a0-9e63-16b1586af00e",
   "metadata": {},
   "source": [
    "Number of users replied to in our dataset, counting multiplicity (this is the number of relations added to the KG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "2714f635-e5e2-4ffa-93bd-18545c5fbf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991\n"
     ]
    }
   ],
   "source": [
    "# Count the multiplicity of each user in the list\n",
    "user_counts = Counter(all_replied_users)\n",
    "\n",
    "# Find the intersection of the list and set of users\n",
    "intersection_users = set(all_replied_users) & set(df['user_id'])\n",
    "\n",
    "# Count the multiplicity for each user in the intersection\n",
    "intersection_counts = {user: user_counts[user] for user in intersection_users}\n",
    "\n",
    "print(sum(intersection_counts.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d58212-c972-4cdd-b563-7269baa4e714",
   "metadata": {},
   "source": [
    "Number of tweets that were replied to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e7fb21bd-48f2-4181-bec6-2c764595365e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_replied_tweets=df.dropna(subset='in_reply_to_tweet_id')['in_reply_to_tweet_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9f899063-229e-4bea-bafc-87cdad796c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11226, 10976)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_replied_tweets), len(set(all_replied_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a05be1-fc0f-4a8d-8d9f-3b4551a07ea9",
   "metadata": {},
   "source": [
    "Number of tweets replied to in our dataset (not counting multiplicity, e.g., if a given tweet in our dataset was replied to multiple times, this would become multiple triples, but here we are just counting how many unique tweets that were replied to that are among the unique tweets in our dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "50086df8-23de-4426-83aa-926f2df1bafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "212"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['tweet_id']).intersection(set(all_replied_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "990b86c9-0088-495a-8204-25454630fda6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    }
   ],
   "source": [
    "# Count the multiplicity of each user in the list\n",
    "user_counts = Counter(all_replied_tweets)\n",
    "\n",
    "# Find the intersection of the list and set of users\n",
    "intersection_users = set(all_replied_tweets) & set(df['tweet_id'])\n",
    "\n",
    "# Count the multiplicity for each user in the intersection\n",
    "intersection_counts = {user: user_counts[user] for user in intersection_users}\n",
    "\n",
    "print(sum(intersection_counts.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c9f87-9588-42ef-a0c8-e7963ca824a6",
   "metadata": {},
   "source": [
    "Number of tweets that were quoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "496416ee-d28e-4022-8fc1-e328780283a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_quoted_tweets = df.dropna(subset='quoted_tweet_id')['quoted_tweet_id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "43c8ff7e-9c4a-4b65-ba34-098716e7dbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8984, 8178)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_quoted_tweets), len(set(all_quoted_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ba360d-d21b-463e-9eda-a6f5dee0fb95",
   "metadata": {},
   "source": [
    "Number of tweets quoted in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eec294f8-b3ab-4a4d-aa9e-7937a4f09daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['tweet_id']).intersection(set(all_quoted_tweets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9324b148-770c-4b68-aa58-dd9a529cc859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# Count the multiplicity of each user in the list\n",
    "user_counts = Counter(all_quoted_tweets)\n",
    "\n",
    "# Find the intersection of the list and set of users\n",
    "intersection_users = set(all_quoted_tweets) & set(df['tweet_id'])\n",
    "\n",
    "# Count the multiplicity for each user in the intersection\n",
    "intersection_counts = {user: user_counts[user] for user in intersection_users}\n",
    "\n",
    "print(sum(intersection_counts.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefdebf7-564e-4d59-8031-8071798c4f58",
   "metadata": {},
   "source": [
    "Number of users that were mentioned (counting multiplicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e53a8313-bfe0-40ef-b486-e18db3d10f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mentions = df[df[\"mentions\"].apply(lambda x: len(x) > 0)]['mentions'].explode().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "adf968cf-6550-4358-bd90-d4dd4346f306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23195, 13011)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_mentions), len(set(all_mentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03a013-8543-4ba8-a33a-0319fd42591a",
   "metadata": {},
   "source": [
    "Number of mentioned users in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f0fa6dfb-e2f1-4074-92b3-81073333b445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df['user_id']).intersection(set(all_mentions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "afcbb5f0-57cf-4e90-bc51-cdc33faded80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "461\n"
     ]
    }
   ],
   "source": [
    "# Count the multiplicity of each user in the list\n",
    "user_counts = Counter(all_mentions)\n",
    "\n",
    "# Find the intersection of the list and set of users\n",
    "intersection_users = set(all_mentions) & set(df['user_id'])\n",
    "\n",
    "# Count the multiplicity for each user in the intersection\n",
    "intersection_counts = {user: user_counts[user] for user in intersection_users}\n",
    "\n",
    "print(sum(intersection_counts.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91869b23-902b-4e93-8d93-e4b883b610d6",
   "metadata": {},
   "source": [
    "**From the analysis above, we will proceed by creating only triples between tweets that reply to users and tweets that mention users.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d5288-0ca0-4ad9-8666-2b0d4de11eeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tweet to User (reply) Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64c3c11c-6468-4f68-8313-af4407e323c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2959/2959 [00:00<00:00, 287863.47it/s]\n"
     ]
    }
   ],
   "source": [
    "reply_relations = []\n",
    "\n",
    "for tweet in tqdm(tweet_dict):\n",
    "    replied_user = tweet['in_reply_to_user_id']\n",
    "    \n",
    "    if not np.isnan(replied_user):\n",
    "        if (replied_user, 'u') in entities:\n",
    "\n",
    "            relation = []\n",
    "            relation.append(entity2id[(tweet['tweet_id'], 't')])\n",
    "            relation.append(entity2id[(replied_user, 'u')])\n",
    "            relation.append(relation2id['replied_to'])\n",
    "            # relation.append(1.0)\n",
    "\n",
    "            reply_relations.append(relation)\n",
    "\n",
    "all_relations = [*all_relations, *reply_relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7514ec27-c188-45fe-82c7-9d906a24bd36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fda61c8-334a-4e96-b6ab-ea67334a56e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tweet to User (mention) Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3607148-75be-459d-a028-2f90c367c164",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2959/2959 [00:00<00:00, 451487.71it/s]\n"
     ]
    }
   ],
   "source": [
    "mention_relations = []\n",
    "\n",
    "for tweet in tqdm(tweet_dict):  \n",
    "    for men in tweet['mentions']:\n",
    "        if (men, 'u') in entities:\n",
    "            \n",
    "            relation=[]\n",
    "            relation.append(entity2id[(tweet['tweet_id'], 't')])\n",
    "            relation.append(entity2id[(men, 'u')])\n",
    "            relation.append(relation2id['mentioned'])\n",
    "            # relation.append(1.0)\n",
    "            \n",
    "            mention_relations.append(relation)\n",
    "\n",
    "all_relations = [*all_relations, *mention_relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7746115a-7874-4f60-a92a-5757c4a42890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d98fb5-c6d6-4ec4-881a-7d5038055603",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tweet-to-? Triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fedb5d-ac8d-45fb-b388-586e81437eb4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tweet-to-Date Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54f52f8f-a86c-41b5-a36c-16ff8104402a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2959/2959 [00:00<00:00, 340857.04it/s]\n"
     ]
    }
   ],
   "source": [
    "tweet_date_relations = []\n",
    "\n",
    "for tweet in tqdm(tweet_dict):\n",
    "        \n",
    "    relation = []\n",
    "    relation.append(entity2id[(tweet['tweet_id'], 't')])\n",
    "    relation.append(entity2id[tweet['date']])\n",
    "    relation.append(relation2id['tweeted_on'])\n",
    "    # relation.append(1.0)\n",
    "        \n",
    "    tweet_date_relations.append(relation)\n",
    "\n",
    "all_relations = [*all_relations, *tweet_date_relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76a1de4f-084c-4df8-ad84-3f1858d3d2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3055"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ab349-c163-4f79-8548-8ce9e93040e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tweet-to-Topic Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdd3d809-a058-467f-a42c-2dca2220bc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 2959/2959 [00:00<00:00, 118218.62it/s]\n"
     ]
    }
   ],
   "source": [
    "tweet_topic_relations = []\n",
    "\n",
    "for tweet in tqdm(tweet_dict):\n",
    "    for top in top_list:\n",
    "        if tweet[f'{top}'] >= 0.01:\n",
    "            \n",
    "            relation = []\n",
    "            relation.append(entity2id[(tweet['tweet_id'], 't')])\n",
    "            relation.append(entity2id[top2name[top]])\n",
    "            relation.append(relation2id['in_topic'])\n",
    "            relation.append(tweet[f'{top}'])\n",
    "            \n",
    "            tweet_topic_relations.append(relation)\n",
    "\n",
    "all_relations = [*all_relations, *tweet_topic_relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "222b503f-13b7-4e1c-a07a-4d2431444b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6225"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f96e1-a373-4988-8196-39e745770e3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other Triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8139820f-adc4-48ea-86ea-91257f3b35d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### User-to-Tweet Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ed25d50-20a1-4f34-bd68-e6a7b485675c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 2959/2959 [00:00<00:00, 39549.36it/s]\n"
     ]
    }
   ],
   "source": [
    "user_tweet_relations = []\n",
    "\n",
    "for tweet in tqdm(tweet_dict):\n",
    "        \n",
    "    relation = []\n",
    "    relation.append(entity2id[(tweet['user_id'], 'u')])\n",
    "    relation.append(entity2id[(tweet['tweet_id'], 't')])\n",
    "    relation.append(relation2id['tweeted'])\n",
    "    # relation.append(1.0)\n",
    "\n",
    "    user_tweet_relations.append(relation)\n",
    "        \n",
    "all_relations = [*all_relations, *user_tweet_relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f52291b-f43c-4a7d-be5d-d0d9183c3ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9184"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f6a24-b115-4d85-81ec-fb1d0b74e108",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Crime-to-Date Triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "83455466-9686-4207-914c-43d02d9d4965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 418/418 [00:00<00:00, 383888.56it/s]\n"
     ]
    }
   ],
   "source": [
    "crime_date_relations = []\n",
    "\n",
    "for crime in tqdm(crime_dict):\n",
    "    \n",
    "    relation = []\n",
    "    relation.append(entity2id[(crime['incident_id'], 'c')])\n",
    "    relation.append(entity2id[crime['incident_date']])\n",
    "    relation.append(relation2id['occurred_on']) \n",
    "    relation.append(1.0)\n",
    "    \n",
    "    crime_date_relations.append(relation)\n",
    "\n",
    "all_relations = [*all_relations, *crime_date_relations]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a1f1df-c2b6-498c-8001-e7a5a3093468",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d659a0fe-9056-4bcf-94dc-0ac018b6641c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9184"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de201054-87fa-4844-9da2-cf3051d80865",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50de2e33-8d69-44d2-ae75-0e9e178140f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 9184/9184 [00:00<00:00, 360310.99it/s]\n"
     ]
    }
   ],
   "source": [
    "for trip in tqdm(all_relations):\n",
    "    relation = []\n",
    "    if isinstance(id2entity[trip[0]], tuple):\n",
    "        relation.append((int(id2entity[trip[0]][0]), id2entity[trip[0]][1]))\n",
    "    else:    \n",
    "        relation.append(id2entity[trip[0]])\n",
    "    \n",
    "    if isinstance(id2entity[trip[1]], tuple):\n",
    "        relation.append((int(id2entity[trip[1]][0]), id2entity[trip[1]][1]))\n",
    "    else:\n",
    "        relation.append(id2entity[trip[1]])\n",
    "    relation.append(id2relation[trip[2]])\n",
    "    try:\n",
    "        relation.append(trip[3])\n",
    "    except:\n",
    "        relation.append(np.nan)\n",
    "    \n",
    "    all_relations2.append(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a047b580-3ee2-4ae3-a37c-899b48d5c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations_df = pd.DataFrame(all_relations2, columns=['head', 'tail', 'relation', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dac3531-ea22-44eb-bf11-f3692e330e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>tail</th>\n",
       "      <th>relation</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1239576949934047232, t)</td>\n",
       "      <td>(2808590695, u)</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1240535441847095296, t)</td>\n",
       "      <td>(1060564414116450432, u)</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1243967634057510912, t)</td>\n",
       "      <td>(3255342379, u)</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1245940455558098944, t)</td>\n",
       "      <td>(1021673051409117184, u)</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1253083733269213184, t)</td>\n",
       "      <td>(43906698, u)</td>\n",
       "      <td>replied_to</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9179</th>\n",
       "      <td>(28959352, u)</td>\n",
       "      <td>(1405269981244248064, t)</td>\n",
       "      <td>tweeted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9180</th>\n",
       "      <td>(43989926, u)</td>\n",
       "      <td>(1405316297261342720, t)</td>\n",
       "      <td>tweeted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9181</th>\n",
       "      <td>(22114879, u)</td>\n",
       "      <td>(1405321378530684928, t)</td>\n",
       "      <td>tweeted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9182</th>\n",
       "      <td>(1398721996502884352, u)</td>\n",
       "      <td>(1405342254370222080, t)</td>\n",
       "      <td>tweeted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>(1368715374645026816, u)</td>\n",
       "      <td>(1405369335984451584, t)</td>\n",
       "      <td>tweeted</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9184 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          head                      tail    relation  weight\n",
       "0     (1239576949934047232, t)           (2808590695, u)  replied_to     NaN\n",
       "1     (1240535441847095296, t)  (1060564414116450432, u)  replied_to     NaN\n",
       "2     (1243967634057510912, t)           (3255342379, u)  replied_to     NaN\n",
       "3     (1245940455558098944, t)  (1021673051409117184, u)  replied_to     NaN\n",
       "4     (1253083733269213184, t)             (43906698, u)  replied_to     NaN\n",
       "...                        ...                       ...         ...     ...\n",
       "9179             (28959352, u)  (1405269981244248064, t)     tweeted     NaN\n",
       "9180             (43989926, u)  (1405316297261342720, t)     tweeted     NaN\n",
       "9181             (22114879, u)  (1405321378530684928, t)     tweeted     NaN\n",
       "9182  (1398721996502884352, u)  (1405342254370222080, t)     tweeted     NaN\n",
       "9183  (1368715374645026816, u)  (1405369335984451584, t)     tweeted     NaN\n",
       "\n",
       "[9184 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_relations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab0282d1-0ed4-45a9-a3f9-5acc2d422395",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_relations_df.to_csv('./data/kg_hispanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a75819-943c-4ed1-8f24-43610cec6747",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
